A submission to the LLM Classification Finetuning Kaggle competition. The implementation utilizes Pytorch and Huggingface to finetune a pretrained RoBERTa LLM for a human preference classification task.

Training on a Kaggle dataset, I was tasked with retraining the model to classify text pairs based-on how well they answer a query. The result was a model that could distinguish between good and bad responses. In this case, responses were written by LLMâ€™s in response to queries.

I had to make several decisions to improve model performance. I had to select an LLM that would operate on my local machine while still being able to achieve acceptable performance in the challenging task. I also manually wrote a script that attached a classification head to the encoder model, loaded the kaggle data into the training pipeline, and trained the model using Pytorch. I encountered two major difficulties. First, I discovered that the dataset was, in fact, highly nested, where inputs generally contained several requests and outputs contained several responses. I built a custom dataloader with a custom collate function to unpack nested training data during batching. Unfortunately, I found this was unable to generate improved model performance, at least in the first handful of attempts. I was also tasked with adjusting hyperparameters, batch size, learning rate, etc. to find an optimal combination that led to the best performance on the validation set.

I was able to achieve a moderate fit to the data with a validation loss (cat. Cross entropy) of 1.035 corresponding to an accuracy of ~47%, above chance which was 33%. I learned a significant amount about LLM finetuning through this process. First, I was surprised that denesting the data provided such little improvement to training. If I were to do this again, I would instead focus on cleaning up, then concatenating nested texts and challenging myself to begin with better checkpoints (perhaps Qwen as I saw other successful submissions apply) so I could expand the context window. I am also interested in exploring more tools such as warm-up which may improve gradient descent.
