{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daf91daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c513427f",
   "metadata": {},
   "source": [
    "The following notebook is mostly unannotated.  \n",
    "\n",
    "Starting with the **RoBERTa checkpoint**, the following script:  \n",
    "- Builds a **PyTorch dataloader**  \n",
    "- Adds a **classification head** to the RoBERTa model  \n",
    "- Designs a **forward propagation** routine that embeds text pairs, concatenates embeddings, and predicts human preferences over the combined embedding sequences  \n",
    "\n",
    "Finally, it performs **gradient descent** with:  \n",
    "- Batch size = `16`  \n",
    "- Optimizer = **Adam**  \n",
    "- Learning rate = `5e-5`  \n",
    "- Weight decay = `15e-2`  \n",
    "\n",
    "**Results:**  \n",
    "- Training fit — *CCE = 0.9758203125, Accuracy = 51.8%*  \n",
    "- Validation fit — *CCE = 1.0341614906832297, Accuracy = 48%*  \n",
    "- Initial metrics — *Loss ≈ 1.10, Accuracy ≈ 33%*  \n",
    "\n",
    "These results demonstrate the ability of a **pretrained encoder model (2019)** to be fine-tuned for modeling and predicting **human attitudes and judgments**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba9e1224-f7c3-4386-8e79-47b9e004329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c7aa9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  [\"Is it morally right to try to have a certain...   \n",
       "1  [\"What is the difference between marriage lice...   \n",
       "2  [\"explain function calling. how would you call...   \n",
       "3  [\"How can I create a test set for a very rare ...   \n",
       "4  [\"What is the best way to travel from Tel-Aviv...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  [\"The question of whether it is morally right ...   \n",
       "1  [\"A marriage license is a legal document that ...   \n",
       "2  [\"Function calling is the process of invoking ...   \n",
       "3  [\"Creating a test set for a very rare category...   \n",
       "4  [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1  [\"A marriage license and a marriage certificat...               0   \n",
       "2  [\"Function calling is the process of invoking ...               0   \n",
       "3  [\"When building a classifier for a very rare c...               1   \n",
       "4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
       "\n",
       "   winner_model_b  winner_tie  \n",
       "0               0           0  \n",
       "1               1           0  \n",
       "2               0           1  \n",
       "3               0           0  \n",
       "4               1           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.read_csv('llm_classification_finetuning/train.csv').iloc[:,3:]\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8a10dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "splitter = ShuffleSplit(n_splits=1, test_size = .1, random_state=1234567)\n",
    "\n",
    "for train_idx, validation_idx in splitter.split(training_data):\n",
    "    train = training_data.iloc[train_idx]\n",
    "    val = training_data.iloc[validation_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f89f34d-7a0d-4014-9f22-c137ff565656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24b32c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"FacebookAI/roberta-base\"\n",
    "dtype = torch.bfloat16\n",
    "device = torch.device('cuda')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "encoder = AutoModel.from_pretrained(model_id,\n",
    "                                    torch_dtype = dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f1c7c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ClassifierDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=None, pad_token_id=tokenizer.pad_token_id):\n",
    "        self.data = dataframe\n",
    "        self.pad_token_id = pad_token_id\n",
    "\n",
    "        self.encoded_texts = [encoded_text for row in \n",
    "                              [[tokenizer.encode('Prompt: ' + row['prompt']),\n",
    "                                tokenizer.encode('Response A: ' + row['response_a']),\n",
    "                                tokenizer.encode('Response B: ' + row['response_b'])]\n",
    "                                for _, row in self.data.iterrows()] for encoded_text in row]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length] for encoded_text in self.encoded_texts #truncation\n",
    "            ]\n",
    "\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text)) for encoded_text in self.encoded_texts #padding\n",
    "        ]\n",
    "\n",
    "        self.triplet_encoded_texts = [np.array([\n",
    "            self.encoded_texts[i] + [2],\n",
    "            self.encoded_texts[i+1] + [2],\n",
    "            self.encoded_texts[i+2] + [2]\n",
    "            ])\n",
    "            for i in range(0, len(self.encoded_texts), 3)]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        triplet = self.triplet_encoded_texts[index]\n",
    "\n",
    "        Prompt = torch.tensor(triplet[0], dtype=torch.long)\n",
    "        prompt_mask = (Prompt != self.pad_token_id).long()\n",
    "\n",
    "        Response_A = torch.tensor(triplet[1], dtype=torch.long)\n",
    "        response_A_mask = (Response_A != self.pad_token_id).long()\n",
    "\n",
    "        Response_B = torch.tensor(triplet[2], dtype=torch.long)\n",
    "        response_B_mask = (Response_B != self.pad_token_id).long()\n",
    "\n",
    "        \n",
    "        inputs = [Prompt, Response_A, Response_B]\n",
    "        masks = [prompt_mask, response_A_mask, response_B_mask]\n",
    "        label = self.data.iloc[index][[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].astype(int).values\n",
    "        \n",
    "        return (\n",
    "            inputs,\n",
    "            masks,\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _longest_encoded_length(self):\n",
    "        max_length=0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length>max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n",
    "\n",
    "max_length = 511\n",
    "\n",
    "train_dataset = ClassifierDataset(train, tokenizer, max_length=max_length)\n",
    "val_dataset = ClassifierDataset(val, tokenizer, max_length=max_length)\n",
    "\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449298e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(1234567)\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = num_workers,\n",
    "    drop_last = True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset = val_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = num_workers,\n",
    "    drop_last = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e07289c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3233\n",
      "Train Inputs Batch Shape:  torch.Size([16, 512])\n",
      "Train Target Batch Shape:  torch.Size([16, 3])\n",
      "359\n",
      "Validation Inputs Batch Shape:  torch.Size([16, 512])\n",
      "Validation Target Batch Shape:  torch.Size([16, 3])\n"
     ]
    }
   ],
   "source": [
    "for inputs, masks, labels in train_loader:\n",
    "    pass\n",
    "\n",
    "print(len(train_loader))\n",
    "print(\"Train Inputs Batch Shape: \", inputs[0].shape)\n",
    "print(\"Train Target Batch Shape: \", labels.shape )\n",
    "\n",
    "for inputs, masks, labels in val_loader:\n",
    "    pass\n",
    "\n",
    "print(len(val_loader))\n",
    "print(\"Validation Inputs Batch Shape: \", inputs[0].shape)\n",
    "print(\"Validation Target Batch Shape: \", labels.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e05d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "encoder.score = nn.Identity() # Silence the original automodel output layer\n",
    "\n",
    "class TripletClassifier(torch.nn.Module):\n",
    "    def __init__(self, encoder, hidden_dim_1, output_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.hidden_dim_1 = hidden_dim_1\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # Write a new classification head (simple)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim_1, self.output_dim),\n",
    "        )\n",
    "\n",
    "    # Write encoder model\n",
    "\n",
    "    def encode(self, input_ids, attention_mask):\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        emb = outputs.pooler_output\n",
    "\n",
    "        return emb\n",
    "\n",
    "    # Write a forward pass that encodes each of the three inputs,\n",
    "    # concats the sequence encodings, then classifies them as a unit.\n",
    "\n",
    "    def forward(self, inputs, attention_masks):\n",
    "        # Extract inputs and masks\n",
    "        prompt = inputs[0]\n",
    "        response_A = inputs[1]\n",
    "        response_B = inputs[2]\n",
    "\n",
    "        prompt_mask = attention_masks[0]\n",
    "        response_A_mask = attention_masks[1]\n",
    "        response_B_mask = attention_masks[2]\n",
    "\n",
    "        # Pass each input to RoBERTa and get encodings\n",
    "        prompt_emb = self.encode(input_ids = prompt, attention_mask = prompt_mask)\n",
    "        response_A_emb = self.encode(input_ids = response_A, attention_mask = response_A_mask)\n",
    "        response_B_emb = self.encode(input_ids = response_B, attention_mask = response_B_mask)\n",
    "\n",
    "        combined = torch.cat([prompt_emb, response_A_emb, response_B_emb], dim=1) # concatenate embeddings\n",
    "\n",
    "        logits = self.classifier(combined) # classify embeddings\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "173d08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TripletClassifier(encoder = encoder, hidden_dim_1 = 3 * 768, output_dim = 3)\n",
    "\n",
    "model = model.to(device).to(dtype)\n",
    "\n",
    "inputs, masks = [i.to(device) for i in inputs], [i.to(device) for i in masks]\n",
    "example_output = model.forward(inputs, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc3ad1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Output Shape:  torch.Size([16, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Example Output Shape: \", example_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "59e15f47-5846-4aca-b2e8-c6e94f933ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TripletClassifier(\n",
      "  (encoder): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): RobertaPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=2304, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e6d6cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.encoder.embeddings.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.encoder.encoder.layer[10].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.encoder.encoder.layer[11].parameters():\n",
    "    param.requires_grad = True   \n",
    "\n",
    "for param in model.encoder.pooler.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cf8a572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "    \n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (inputs, attention_masks, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            inputs[:] = [t.to(device) for t in inputs]\n",
    "            attention_masks[:] = [t.to(device) for t in attention_masks]\n",
    "            target_batch = target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(inputs, attention_masks = attention_masks)\n",
    "           \n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "            target_batch = torch.argmax(target_batch, dim=-1)\n",
    "            \n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "            num_examples += logits.shape[0]\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "696ae2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.296875\n",
      "Validation accuracy:  0.378125\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device = device, num_batches=20)\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "\n",
    "validation_accuracy = calc_accuracy_loader(val_loader,  model, device = device, num_batches=20)\n",
    "print(\"Validation accuracy: \", validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3eda525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(inputs, attention_masks, target_batch, model):\n",
    "    target_batch = target_batch.argmax(dim=1)\n",
    "    logits = model(inputs,attention_masks=attention_masks)\n",
    "    \n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader)==0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (inputs, attention_masks, target_batch) in enumerate(data_loader):\n",
    "        inputs[:] = [t.to(device) for t in inputs]\n",
    "        attention_masks[:] = [t.to(device) for t in attention_masks]\n",
    "        target_batch = target_batch.to(device)\n",
    "\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(inputs, attention_masks, target_batch, model)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425d340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = calc_loss_loader(train_loader, model, device, num_batches = 20)\n",
    "print(\"Train Loss: \", train_loss)\n",
    "\n",
    "validation_loss = calc_loss_loader(val_loader,model, device, num_batches = 20)\n",
    "print(\"Validation Loss: \", validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f4ecee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches = eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches = eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "87a0d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs):\n",
    "\n",
    "    # Initialize lists\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Set model to training mode\n",
    "\n",
    "        for inputs, attention_masks, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            inputs[:], attention_masks[:], target_batch = [t.to(device) for t in inputs], [t.to(device) for t in attention_masks], target_batch.to(device)\n",
    "\n",
    "            loss = calc_loss_batch(inputs, attention_masks, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "\n",
    "            optimizer.step()\n",
    "            examples_seen += inputs[0].shape[0]\n",
    "            global_step += 1\n",
    "\n",
    "            # Evaluation step\n",
    "            if global_step % 50 == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter = 30)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "  \n",
    "            if global_step % 500 == 0:\n",
    "                # Calculate accuracy after each epoch\n",
    "                train_accuracy = calc_accuracy_loader(train_loader,model,device, num_batches = 30)\n",
    "                val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches = 30)\n",
    "                print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "                print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "                train_accs.append(train_accuracy)\n",
    "                val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2052d4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.974, Val loss 1.012\n",
      "Training accuracy: 49.38% | Validation accuracy: 49.27%\n",
      "Ep 1 (Step 000050): Train loss 0.997, Val loss 1.056\n",
      "Ep 1 (Step 000100): Train loss 1.007, Val loss 1.036\n",
      "Ep 1 (Step 000150): Train loss 1.006, Val loss 1.055\n",
      "Ep 1 (Step 000200): Train loss 0.989, Val loss 1.069\n",
      "Ep 1 (Step 000250): Train loss 1.005, Val loss 0.997\n",
      "Ep 1 (Step 000300): Train loss 0.988, Val loss 1.027\n",
      "Ep 1 (Step 000350): Train loss 0.980, Val loss 1.009\n",
      "Ep 1 (Step 000400): Train loss 1.009, Val loss 1.015\n",
      "Ep 1 (Step 000450): Train loss 0.976, Val loss 1.037\n",
      "Ep 1 (Step 000500): Train loss 0.990, Val loss 1.026\n",
      "Training accuracy: 49.58% | Validation accuracy: 46.04%\n",
      "Ep 1 (Step 000550): Train loss 0.991, Val loss 1.054\n",
      "Ep 1 (Step 000600): Train loss 1.002, Val loss 1.029\n",
      "Ep 1 (Step 000650): Train loss 0.965, Val loss 1.049\n",
      "Ep 1 (Step 000700): Train loss 0.997, Val loss 1.038\n",
      "Ep 1 (Step 000750): Train loss 0.969, Val loss 1.024\n",
      "Ep 1 (Step 000800): Train loss 1.014, Val loss 1.059\n",
      "Ep 1 (Step 000850): Train loss 0.994, Val loss 1.053\n",
      "Ep 1 (Step 000900): Train loss 0.978, Val loss 1.036\n",
      "Ep 1 (Step 000950): Train loss 1.007, Val loss 1.011\n",
      "Ep 1 (Step 001000): Train loss 1.000, Val loss 1.037\n",
      "Training accuracy: 51.98% | Validation accuracy: 49.17%\n",
      "Ep 1 (Step 001050): Train loss 0.961, Val loss 1.037\n",
      "Ep 1 (Step 001100): Train loss 0.970, Val loss 1.020\n",
      "Ep 1 (Step 001150): Train loss 1.011, Val loss 1.071\n",
      "Ep 1 (Step 001200): Train loss 0.936, Val loss 1.027\n",
      "Ep 1 (Step 001250): Train loss 0.981, Val loss 1.035\n",
      "Training completed in 5.55 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(1234567)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=15e-2)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time)/60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38efd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.517625\n",
      "0.4765139751552795\n",
      "0.9758203125\n",
      "1.0341614906832297\n"
     ]
    }
   ],
   "source": [
    "print(calc_accuracy_loader(train_loader, model, device = device, num_batches=None))\n",
    "print(calc_accuracy_loader(val_loader, model, device = device, num_batches=None))\n",
    "\n",
    "print(calc_loss_loader(train_loader, model, device, num_batches=None))\n",
    "print(calc_loss_loader(val_loader, model, device, num_batches=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf07720f-0dc0-4ca5-89f7-ea0986203566",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
